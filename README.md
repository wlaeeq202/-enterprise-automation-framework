## ğŸ§° Tech Stack

## ğŸ—ºï¸ Automation Architecture Overview (UI â€¢ API â€¢ ETL)

## ğŸ§© Enterprise Data Simulation (Snowflake-Style ETL)

This framework is split into **UI**, **API**, and **ETL/Data** layers to mirror real enterprise testing.

### ğŸ“Œ Responsibility Map (What runs where)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Test Orchestrator                       â”‚
â”‚          (Local Run or GitHub Actions CI)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI Automation Layer                                      â”‚
â”‚ src/ui/                                                  â”‚
â”‚ â€¢ Playwright UI tests (POM)                              â”‚
â”‚ â€¢ User flows, navigation, regressions                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Automation Layer                                     â”‚
â”‚ src/api/tests/                                           â”‚
â”‚ â€¢ REST API tests (GET/POST/PATCH/DELETE)                 â”‚
â”‚ â€¢ Status codes, payloads, payload validation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETL / Snowflake-Style Data Simulation                    â”‚
â”‚ enterprise-data-simulation/snowflake/                    â”‚
â”‚ â€¢ Raw data generation                                    â”‚
â”‚ â€¢ Transform logic (fact outputs)                         â”‚
â”‚ â€¢ Data reconciliation + quality checks                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reports & CI Artifacts                                   â”‚
â”‚ â€¢ Playwright HTML report                                 â”‚
â”‚ â€¢ Logs, traces, screenshots                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
### ğŸ” Execution Flow (Visual)

```mermaid
flowchart TD
  A[Developer / GitHub Actions] --> B[npm ci + Playwright install]
  B --> C[Test Orchestration]

  subgraph UI[UI Automation]
    U1[src/ui] --> U2[Playwright Tests]
    U2 --> U3[UI Assertions + Artifacts]
  end

  subgraph API[API Automation]
    A1[src/api/tests] --> A2[src/api/clients]
    A2 --> A3[REST Assertions]
  end

  subgraph ETL[ETL / Snowflake Simulation]
    E1[snowflake/data/raw_costs.json]
    E2[generate_costs.js]
    E3[transform_costs.js]
    E4[snowflake_fact_costs.json]
    E5[validate_transformation.js]
    E1 --> E2 --> E3 --> E4 --> E5
  end

  subgraph Backend[C# Backend Simulation]
    D1[enterprise-data-simulation/csharp-api] --> A2
  end

  C --> U1
  C --> A1
  C --> E1

  U3 --> R[Playwright Report + CI Artifacts]
  A3 --> R
  E5 --> R  
```

```md

This repository includes a **deterministic, CI-safe simulation of a Snowflake ETL pipeline**.

It demonstrates how an SDET validates **data correctness and performance**, not just UI or API responses.
```

###  Folder Structure

```text
enterprise-data-simulation/
â””â”€ snowflake/
   â”œâ”€ data/
   â”‚  â”œâ”€ raw_costs.json
   â”‚  â””â”€ snowflake_fact_costs.json
   â”œâ”€ scripts/
   â”‚  â”œâ”€ generate_costs.js
   â”‚  â”œâ”€ transform_costs.js
   â”‚  â””â”€ validate_transformation.js
   â”œâ”€ perf/
   â”‚  â””â”€ baseline.json
   â””â”€ README.md
```

```text
.github/workflows/etl-validate.yml
```
###  What the ETL Workflow Does

1. Generate representative raw data (5,000 rows)
2. Transform raw â†’ fact output (GROUP BY + SUM)
3. Independently re-aggregate raw data
4. Compare expected vs actual results
5. Measure execution runtime
6. Fail CI if:
   - Data mismatches are detected
   - Runtime regression exceeds allowed threshold

---

##  Runtime Regression Protection

In addition to validating data correctness, the ETL pipeline also protects
against **performance regressions**.

### How Runtime Is Evaluated

- ETL execution time is measured during CI
- A historical baseline is used when available
- Safe defaults are applied when no baseline exists

```text
enterprise-data-simulation/snowflake/perf/baseline.json
```

### Why CI Uses 5,000 Rows (and Not Millions)

HealthMonix-style pipelines can process **millions of rows**, but CI must stay fast.

This repo intentionally uses **5,000 representative rows** in PR builds to:
- Catch ETL logic regressions quickly (GROUP BY / SUM rules)
- Keep pull request pipelines fast and reliable
- Prevent deployments from slowing down due to validation suites

### How This Scales to Millions

The same scripts work for larger datasets by changing an environment variable:

- PR / CI: `ROWS=5000` (fast correctness + quick runtime signal)
- Nightly / scheduled: `ROWS=100000+` (heavier performance validation)

This is the same strategy enterprise teams use:
**fast correctness checks per commit + scheduled performance gates**

---

##  Run ETL Locally

### 1) Install dependencies
```bash
npm ci
```
```bash
npm run etl:generate
npm run etl:transform
npm run etl:validate
```
```bash
ROWS=10000 npm run etl:generate
npm run etl:transform
npm run etl:validate
```
#### macOS / Linux
```bash
ROWS=10000 npm run etl:generate
npm run etl:transform
npm run etl:validate
```

#### Windows
```powershell
$env:ROWS="10000"
npm run etl:generate
npm run etl:transform
npm run etl:validate
```

---

## â–¶ï¸ Run UI + API Locally (Playwright)

### 1) Install dependencies
```bash
npm ci
npx playwright install
```
```bash
npm test
```
```bash
npx playwright test src/ui
```
```bash
npx playwright test src/api/tests
```
```bash
npx playwright test src/ui --headed
```
```bash
npx playwright show-report
```
## â–¶ï¸ Run Legacy UI (Selenium)

### Run Selenium example tests
```bash
npm run test:selenium
```

## â–¶ï¸ Run Local C# COST API (Optional Integration)

```bash
cd enterprise-data-simulation/csharp-api
dotnet restore
dotnet run
```

